{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37b40739-4856-483b-a3d6-5f2306998b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapetube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c27cb30-16e4-4b76-8587-637d129e96c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video ID: dqOb6GHm8_M\n",
      "Video Title: {'runs': [{'text': 'Monsoon Special Romantic Hits | Video Jukebox | #bollywoodsongs'}], 'accessibility': {'accessibilityData': {'label': 'Monsoon Special Romantic Hits | Video Jukebox | #bollywoodsongs by Ishtar Music 3 days ago 36 minutes 17,977 views'}}}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'description'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideo ID:\u001b[39m\u001b[38;5;124m\"\u001b[39m, video[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideoId\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideo Title:\u001b[39m\u001b[38;5;124m\"\u001b[39m, video[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideo Description:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mvideo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdescription\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideo Thumbnail:\u001b[39m\u001b[38;5;124m\"\u001b[39m, video[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthumbnail\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'description'"
     ]
    }
   ],
   "source": [
    "# Retrieve videos from a channel\n",
    "channel_id = \"UCWi_65E_L8tQZ34C6wVAlpQ\"\n",
    "videos = scrapetube.get_channel(channel_id)\n",
    "\n",
    "# Print video details\n",
    "for video in videos:\n",
    "    print(\"Video ID:\", video['videoId'])\n",
    "    print(\"Video Title:\", video['title'])\n",
    "    print(\"Video Description:\", video['description'])\n",
    "    print(\"Video Thumbnail:\", video['thumbnail'])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c040a92a-7b06-4bf9-9bf2-cd4168683e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import scrapetube\n",
    "\n",
    "# Retrieve videos from a channel\n",
    "channel_id = \"UCWi_65E_L8tQZ34C6wVAlpQ\"\n",
    "videos = scrapetube.get_channel(channel_id)\n",
    "\n",
    "# Open a CSV file in write mode\n",
    "with open('video_details.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['Video ID', 'Video Title', 'Video Description', 'Video Thumbnail']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write the video details to the CSV file\n",
    "    for video in videos:\n",
    "        writer.writerow({\n",
    "            'Video ID': video.get('videoId', ''),\n",
    "            'Video Title': video.get('title', ''),\n",
    "            'Video Description': video.get('description', ''),\n",
    "            'Video Thumbnail': video.get('thumbnail', '')\n",
    "        })\n",
    "\n",
    "print(\"CSV file generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4c09c1-9fd4-4e8c-92aa-93f092dcd25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapetube\n",
    "import sys\n",
    "\n",
    "path = '_list.txt'\n",
    "\n",
    "print('**********************\\n')\n",
    "print(\"The result will be saved in '_list.txt' file.\")\n",
    "print(\"Enter Channel ID:\")\n",
    "\n",
    "# Prints the output in the console and into the '_list.txt' file.\n",
    "class Logger:\n",
    " \n",
    "    def __init__(self, filename):\n",
    "        self.console = sys.stdout\n",
    "        self.file = open(filename, 'w')\n",
    " a\n",
    "    def write(self, message):\n",
    "        self.console.write(message)\n",
    "        self.file.write(message)\n",
    " \n",
    "    def flush(self):\n",
    "        self.console.flush()\n",
    "        self.file.flush()\n",
    "\n",
    "sys.stdout = Logger(path)\n",
    "\n",
    "# Strip the: \"https://www.youtube.com/channel/\"\n",
    "channel_id_input = input()\n",
    "channel_id = channel_id_input.strip(\"https://www.youtube.com/channel/\")\n",
    "\n",
    "videos = scrapetube.get_channel(channel_id)\n",
    "\n",
    "for video in videos:\n",
    "    print(\"https://www.youtube.com/watch?v=\"+str(video['videoId']))\n",
    "#    print(video['videoId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18edf795-6ea3-4258-a160-29d520f60850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import scrapetube\n",
    "\n",
    "# Search for videos\n",
    "query = \"python tutorial\"\n",
    "videos = scrapetube.get_search(query)\n",
    "\n",
    "# Open a CSV file in write mode\n",
    "with open('video_details1.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['Video ID', 'Video Title', 'Video Description', 'Video Thumbnail']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write the video details to the CSV file\n",
    "    for video in videos:\n",
    "        writer.writerow({\n",
    "            'Video ID': video.get('videoId', ''),\n",
    "            'Video Title': video.get('title', ''),\n",
    "            'Video Description': video.get('videoDetails', {}).get('description', ''),\n",
    "            'Video Thumbnail': video.get('thumbnail', '')\n",
    "        })\n",
    "\n",
    "print(\"CSV file generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b2f496-fbfe-4be0-8391-b93750661523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import scrapetube\n",
    "\n",
    "# Retrieve videos from a playlist\n",
    "playlist_id = \"PL8mG-RkN2uTwfjD2sxZzR4h3p6DOOZndF\"\n",
    "videos = scrapetube.get_playlist(playlist_id)\n",
    "\n",
    "# Open a CSV file in write mode\n",
    "with open('video_details2.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['Video ID', 'Video Title', 'Video Description', 'Video Thumbnail']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write the video details to the CSV file\n",
    "    for video in videos:\n",
    "        writer.writerow({\n",
    "            'Video ID': video.get('videoId', ''),\n",
    "            'Video Title': video.get('title', ''),\n",
    "            'Video Description': video.get('videoDetails', {}).get('description', ''),\n",
    "            'Video Thumbnail': video.get('thumbnail', '')\n",
    "        })\n",
    "\n",
    "print(\"CSV file generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ed0832-62a9-4408-83c1-2422969a6fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import scrapetube\n",
    "import time\n",
    "\n",
    "def get_short_videos(channel_id: str, limit: int = None, sleep: int = 1):\n",
    "    videos = scrapetube.get_channel(channel_id)\n",
    "    count = 0\n",
    "    for video in videos:\n",
    "        if video.get('shortBylineText'):\n",
    "            yield video\n",
    "            count += 1\n",
    "            if limit and count >= limit:\n",
    "                break\n",
    "        time.sleep(sleep)\n",
    "\n",
    "# Get short videos from a channel\n",
    "channel_id = \"UC6nQxVomo-B2n5-_mYwLv9g\"\n",
    "short_videos = get_short_videos(channel_id, limit=10)\n",
    "\n",
    "# Or, search for short videos\n",
    "# query = \"excel shorts\"\n",
    "# short_videos = scrapetube.get_search(query)\n",
    "\n",
    "# Open a CSV file in write mode\n",
    "with open('short_videos1.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['Video ID', 'Video Title', 'Video Description', 'Video Thumbnail']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write the video details to the CSV file\n",
    "    for video in short_videos:\n",
    "        writer.writerow({\n",
    "            'Video ID': f\"https://www.youtube.com/watch?v={video['videoId']}\",\n",
    "            'Video Title': video['title'],\n",
    "            'Video Description': video.get('description', ''),\n",
    "            'Video Thumbnail': video['thumbnail']\n",
    "        })\n",
    "\n",
    "print(\"CSV file generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71fedba7-8a55-4b4f-a02a-f282d38b54f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'short_videos1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m short_videos \u001b[38;5;241m=\u001b[39m scrapetube\u001b[38;5;241m.\u001b[39mget_search(query)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Print video details\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m video \u001b[38;5;129;01min\u001b[39;00m \u001b[43mshort_videos1\u001b[49m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideo ID:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.youtube.com/watch?v=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideoId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideo Title:\u001b[39m\u001b[38;5;124m\"\u001b[39m, video[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'short_videos1' is not defined"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import scrapetube\n",
    "import time\n",
    "\n",
    "def get_short_videos(channel_id: str, limit: int = None, sleep: int = 1):\n",
    "    videos = scrapetube.get_channel(channel_id)\n",
    "    count = 0\n",
    "    for video in videos:\n",
    "        if video.get('shortBylineText'):\n",
    "            yield video\n",
    "            count += 1\n",
    "            if limit and count >= limit:\n",
    "                break\n",
    "        time.sleep(sleep)\n",
    "\n",
    "# Get short videos from a channel\n",
    "channel_id = \"UC6nQxVomo-B2n5-_mYwLv9g\"\n",
    "short_videos = get_short_videos(channel_id, limit=10)\n",
    "\n",
    "# Or, search for short videos\n",
    "query = \"excel shorts\"\n",
    "short_videos = scrapetube.get_search(query)\n",
    "\n",
    "# Print video details\n",
    "for video in short_videos:\n",
    "    print(\"Video ID:\", f\"https://www.youtube.com/watch?v={video['videoId']}\")\n",
    "    print(\"Video Title:\", video['title'])\n",
    "    print(\"Video Description:\", video.get('description', ''))\n",
    "    print(\"Video Thumbnail:\", video['thumbnail'])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ef2f6b-78ab-42f3-810f-0d58338be1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9365fff-8e96-43c8-b7d5-2e6671bd60c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import scrapetube\n",
    "import time\n",
    "\n",
    "def get_short_videos(channel_id: str, limit: int = None, sleep: int = 1):\n",
    "    videos = scrapetube.get_channel(channel_id)\n",
    "    count = 0\n",
    "    for video in videos:\n",
    "        if video.get('shortBylineText'):\n",
    "            yield video\n",
    "            count += 1\n",
    "            if limit and count >= limit:\n",
    "                break\n",
    "        time.sleep(sleep)\n",
    "\n",
    "# Get short videos from a channel\n",
    "channel_id = \"UC6nQxVomo-B2n5-_mYwLv9g\"\n",
    "short_videos = get_short_videos(channel_id, limit=10000)\n",
    "\n",
    "# Or, search for short videos\n",
    "#query = \"excel shorts\"\n",
    "#short_videos = scrapetube.get_search(query)\n",
    "\n",
    "# Open a CSV file in write mode\n",
    "with open('short_videos3.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['Video ID', 'Video Title', 'Video Description', 'Video Thumbnail']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write the video details to the CSV file\n",
    "    for video in short_videos:\n",
    "        writer.writerow({\n",
    "            'Video ID': f\"https://www.youtube.com/watch?v={video['videoId']}\",\n",
    "            'Video Title': video['title'],\n",
    "            'Video Description': video.get('description', ''),\n",
    "            'Video Thumbnail': video['thumbnail']\n",
    "        })\n",
    "\n",
    "print(\"CSV file generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c76b75-ad49-449a-8d22-542c3ded6bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import scrapetube\n",
    "import time\n",
    "\n",
    "def get_short_videos(channel_id: str, limit: int = None, sleep: int = 1):\n",
    "    videos = scrapetube.get_channel(channel_id)\n",
    "    count = 0\n",
    "    for video in videos:\n",
    "        if video.get('shortBylineText'):\n",
    "            yield video\n",
    "            count += 1\n",
    "            if limit and count >= limit:\n",
    "                break\n",
    "        time.sleep(sleep)\n",
    "\n",
    "# Get short videos from a channel\n",
    "channel_id = \"UC6nQxVomo-B2n5-_mYwLv9g\"\n",
    "short_videos = get_short_videos(channel_id, limit=10)\n",
    "\n",
    "# Or, search for short videos\n",
    "query = \"excel shorts\"\n",
    "short_videos = scrapetube.get_search(query)\n",
    "\n",
    "# Print video details\n",
    "for video in short_videos:\n",
    "    print(\"Video ID:\", f\"https://www.youtube.com/watch?v={video['videoId']}\")\n",
    "    print(\"Video Title:\", video['title'])\n",
    "    print(\"Video Description:\", video.get('description', ''))\n",
    "    print(\"Video Thumbnail:\", video['thumbnail'])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ff0926-9e27-491f-b180-096aef7ae55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import scrapetube\n",
    "\n",
    "# Retrieve videos from a playlist\n",
    "playlist_id = \"PL8mG-RkN2uTwfjD2sxZzR4h3p6DOOZndF\"\n",
    "videos = scrapetube.get_playlist(playlist_id)\n",
    "\n",
    "# Open a CSV file in write mode\n",
    "with open('video_details2.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['Video ID', 'Video Title', 'Video Description', 'Video Thumbnail']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write the video details to the CSV file\n",
    "    for video in videos:\n",
    "        writer.writerow({\n",
    "            'Video ID': video.get('videoId', ''),\n",
    "            'Video Title': video.get('title', ''),\n",
    "            'Video Description': video.get('videoDetails', {}).get('description', ''),\n",
    "            'Video Thumbnail': video.get('thumbnail', '')\n",
    "        })\n",
    "\n",
    "print(\"CSV file generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7886733d-520e-4c13-bc97-54ebfe651c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import scrapetube\n",
    "\n",
    "# Search for videos\n",
    "query = \"python tutorial\"\n",
    "videos = scrapetube.get_search(query)\n",
    "\n",
    "# Open a CSV file in write mode\n",
    "with open('video_details1.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['Video ID', 'Video Title', 'Video Description', 'Video Thumbnail']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write the video details to the CSV file\n",
    "    for video in videos:\n",
    "        writer.writerow({\n",
    "            'Video ID': video.get('videoId', ''),\n",
    "            'Video Title': video.get('title', ''),\n",
    "            'Video Description': video.get('videoDetails', {}).get('description', ''),\n",
    "            'Video Thumbnail': video.get('thumbnail', '')\n",
    "        })\n",
    "\n",
    "print(\"CSV file generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e99ef6d-e5f3-475b-8b24-e469605988d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from typing import Generator\n",
    "\n",
    "import requests\n",
    "from typing_extensions import Literal\n",
    "\n",
    "type_property_map = {\n",
    "    \"videos\": \"videoRenderer\",\n",
    "    \"streams\": \"videoRenderer\",\n",
    "    \"shorts\": \"reelItemRenderer\"\n",
    "}\n",
    "\n",
    "def get_channel(\n",
    "    channel_id: str = None,\n",
    "    channel_url: str = None,\n",
    "    channel_username: str = None,\n",
    "    limit: int = None,\n",
    "    sleep: int = 1,\n",
    "    sort_by: Literal[\"newest\", \"oldest\", \"popular\"] = \"newest\",\n",
    "    content_type: Literal[\"videos\", \"shorts\", \"streams\"] = \"videos\",\n",
    ") -> Generator[dict, None, None]:\n",
    "\n",
    "    \"\"\"Get videos for a channel.\n",
    "\n",
    "    Parameters:\n",
    "        channel_id (``str``, *optional*):\n",
    "            The channel id from the channel you want to get the videos for.\n",
    "            If you prefer to use the channel url instead, see ``channel_url`` below.\n",
    "\n",
    "        channel_url (``str``, *optional*):\n",
    "            The url to the channel you want to get the videos for.\n",
    "            Since there is a few type's of channel url's, you can use the one you want\n",
    "            by passing it here instead of using ``channel_id``.\n",
    "\n",
    "        channel_username (``str``, *optional*):\n",
    "            The username from the channel you want to get the videos for.\n",
    "            Ex. ``LinusTechTips`` (without the @).\n",
    "            If you prefer to use the channel url instead, see ``channel_url`` above.\n",
    "\n",
    "        limit (``int``, *optional*):\n",
    "            Limit the number of videos you want to get.\n",
    "\n",
    "        sleep (``int``, *optional*):\n",
    "            Seconds to sleep between API calls to youtube, in order to prevent getting blocked.\n",
    "            Defaults to 1.\n",
    "\n",
    "        sort_by (``str``, *optional*):\n",
    "            In what order to retrieve to videos. Pass one of the following values.\n",
    "            ``\"newest\"``: Get the new videos first.\n",
    "            ``\"oldest\"``: Get the old videos first.\n",
    "            ``\"popular\"``: Get the popular videos first. Defaults to \"newest\".\n",
    "\n",
    "        content_type (``str``, *optional*):\n",
    "            In order to get content type. Pass one of the following values.\n",
    "            ``\"videos\"``: Videos\n",
    "            ``\"shorts\"``: Shorts\n",
    "            ``\"streams\"``: Streams\n",
    "    \"\"\"\n",
    "\n",
    "    base_url = \"\"\n",
    "    if channel_url:\n",
    "        base_url = channel_url\n",
    "    elif channel_id:\n",
    "        base_url = f\"https://www.youtube.com/channel/{channel_id}\"\n",
    "    elif channel_username:\n",
    "        base_url = f\"https://www.youtube.com/@{channel_username}\"\n",
    "\n",
    "    url = \"{base_url}/{content_type}?view=0&flow=grid\".format(\n",
    "        base_url=base_url,\n",
    "        content_type=content_type,\n",
    "    )\n",
    "    api_endpoint = \"https://www.youtube.com/youtubei/v1/browse\"\n",
    "    videos = get_videos(url, api_endpoint, type_property_map[content_type], limit, sleep, sort_by)\n",
    "    for video in videos:\n",
    "        yield video\n",
    "\n",
    "\n",
    "def get_playlist(\n",
    "    playlist_id: str, limit: int = None, sleep: int = 1\n",
    ") -> Generator[dict, None, None]:\n",
    "\n",
    "    \"\"\"Get videos for a playlist.\n",
    "\n",
    "    Parameters:\n",
    "        playlist_id (``str``):\n",
    "            The playlist id from the playlist you want to get the videos for.\n",
    "\n",
    "        limit (``int``, *optional*):\n",
    "            Limit the number of videos you want to get.\n",
    "\n",
    "        sleep (``int``, *optional*):\n",
    "            Seconds to sleep between API calls to youtube, in order to prevent getting blocked.\n",
    "            Defaults to 1.\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"https://www.youtube.com/playlist?list={playlist_id}\"\n",
    "    api_endpoint = \"https://www.youtube.com/youtubei/v1/browse\"\n",
    "    videos = get_videos(url, api_endpoint, \"playlistVideoRenderer\", limit, sleep)\n",
    "    for video in videos:\n",
    "        yield video\n",
    "\n",
    "\n",
    "def get_search(\n",
    "    query: str,\n",
    "    limit: int = None,\n",
    "    sleep: int = 1,\n",
    "    sort_by: Literal[\"relevance\", \"upload_date\", \"view_count\", \"rating\"] = \"relevance\",\n",
    "    results_type: Literal[\"video\", \"channel\", \"playlist\", \"movie\"] = \"video\",\n",
    ") -> Generator[dict, None, None]:\n",
    "\n",
    "    \"\"\"Search youtube and get videos.\n",
    "\n",
    "    Parameters:\n",
    "        query (``str``):\n",
    "            The term you want to search for.\n",
    "\n",
    "        limit (``int``, *optional*):\n",
    "            Limit the number of videos you want to get.\n",
    "\n",
    "        sleep (``int``, *optional*):\n",
    "            Seconds to sleep between API calls to youtube, in order to prevent getting blocked.\n",
    "            Defaults to 1.\n",
    "\n",
    "        sort_by (``str``, *optional*):\n",
    "            In what order to retrieve to videos. Pass one of the following values.\n",
    "            ``\"relevance\"``: Get the new videos in order of relevance.\n",
    "            ``\"upload_date\"``: Get the new videos first.\n",
    "            ``\"view_count\"``: Get the popular videos first.\n",
    "            ``\"rating\"``: Get videos with more likes first.\n",
    "            Defaults to \"relevance\".\n",
    "\n",
    "        results_type (``str``, *optional*):\n",
    "            What type you want to search for. Pass one of the following values:\n",
    "            ``\"video\"|\"channel\"|\"playlist\"|\"movie\"``. Defaults to \"video\".\n",
    "    \"\"\"\n",
    "\n",
    "    sort_by_map = {\n",
    "        \"relevance\": \"A\",\n",
    "        \"upload_date\": \"I\",\n",
    "        \"view_count\": \"M\",\n",
    "        \"rating\": \"E\",\n",
    "    }\n",
    "\n",
    "    results_type_map = {\n",
    "        \"video\": [\"B\", \"videoRenderer\"],\n",
    "        \"channel\": [\"C\", \"channelRenderer\"],\n",
    "        \"playlist\": [\"D\", \"playlistRenderer\"],\n",
    "        \"movie\": [\"E\", \"videoRenderer\"],\n",
    "    }\n",
    "\n",
    "    param_string = f\"CA{sort_by_map[sort_by]}SAhA{results_type_map[results_type][0]}\"\n",
    "    url = f\"https://www.youtube.com/results?search_query={query}&sp={param_string}\"\n",
    "    api_endpoint = \"https://www.youtube.com/youtubei/v1/search\"\n",
    "    videos = get_videos(\n",
    "        url, api_endpoint, results_type_map[results_type][1], limit, sleep\n",
    "    )\n",
    "    for video in videos:\n",
    "        yield video\n",
    "\n",
    "\n",
    "\n",
    "def get_video(\n",
    "    id: str,\n",
    ") -> dict:\n",
    "\n",
    "    \"\"\"Get a single video.\n",
    "\n",
    "    Parameters:\n",
    "        id (``str``):\n",
    "            The video id from the video you want to get.\n",
    "    \"\"\"\n",
    "\n",
    "    session = get_session()\n",
    "    url = f\"https://www.youtube.com/watch?v={id}\"\n",
    "    html = get_initial_data(session, url)\n",
    "    client = json.loads(\n",
    "        get_json_from_html(html, \"INNERTUBE_CONTEXT\", 2, '\"}},') + '\"}}'\n",
    "    )[\"client\"]\n",
    "    session.headers[\"X-YouTube-Client-Name\"] = \"1\"\n",
    "    session.headers[\"X-YouTube-Client-Version\"] = client[\"clientVersion\"]\n",
    "    data = json.loads(\n",
    "        get_json_from_html(html, \"var ytInitialData = \", 0, \"};\") + \"}\"\n",
    "    )\n",
    "    return next(search_dict(data, \"videoPrimaryInfoRenderer\"))\n",
    "\n",
    "\n",
    "\n",
    "def get_videos(\n",
    "    url: str, api_endpoint: str, selector: str, limit: int, sleep: int, sort_by: str = None\n",
    ") -> Generator[dict, None, None]:\n",
    "    session = get_session()\n",
    "    is_first = True\n",
    "    quit_it = False\n",
    "    count = 0\n",
    "    while True:\n",
    "        if is_first:\n",
    "            html = get_initial_data(session, url)\n",
    "            client = json.loads(\n",
    "                get_json_from_html(html, \"INNERTUBE_CONTEXT\", 2, '\"}},') + '\"}}'\n",
    "            )[\"client\"]\n",
    "            api_key = get_json_from_html(html, \"innertubeApiKey\", 3)\n",
    "            session.headers[\"X-YouTube-Client-Name\"] = \"1\"\n",
    "            session.headers[\"X-YouTube-Client-Version\"] = client[\"clientVersion\"]\n",
    "            data = json.loads(\n",
    "                get_json_from_html(html, \"var ytInitialData = \", 0, \"};\") + \"}\"\n",
    "            )\n",
    "            next_data = get_next_data(data, sort_by)\n",
    "            is_first = False\n",
    "            if sort_by and sort_by != \"newest\": \n",
    "                continue\n",
    "        else:\n",
    "            data = get_ajax_data(session, api_endpoint, api_key, next_data, client)\n",
    "            next_data = get_next_data(data)\n",
    "        for result in get_videos_items(data, selector):\n",
    "            try:\n",
    "                count += 1\n",
    "                yield result\n",
    "                if count == limit:\n",
    "                    quit_it = True\n",
    "                    break\n",
    "            except GeneratorExit:\n",
    "                quit_it = True\n",
    "                break\n",
    "\n",
    "        if not next_data or quit_it:\n",
    "            break\n",
    "\n",
    "        time.sleep(sleep)\n",
    "\n",
    "    session.close()\n",
    "\n",
    "\n",
    "def get_session() -> requests.Session:\n",
    "    session = requests.Session()\n",
    "    session.headers[\n",
    "        \"User-Agent\"\n",
    "    ] = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\"\n",
    "    session.headers[\"Accept-Language\"] = \"en\"\n",
    "    return session\n",
    "\n",
    "def get_initial_data(session: requests.Session, url: str) -> str:\n",
    "    session.cookies.set(\"CONSENT\", \"YES+cb\", domain=\".youtube.com\")\n",
    "    response = session.get(url)\n",
    "\n",
    "    html = response.text\n",
    "    return html\n",
    "\n",
    "\n",
    "def get_ajax_data(\n",
    "    session: requests.Session,\n",
    "    api_endpoint: str,\n",
    "    api_key: str,\n",
    "    next_data: dict,\n",
    "    client: dict,\n",
    ") -> dict:\n",
    "    data = {\n",
    "        \"context\": {\"clickTracking\": next_data[\"click_params\"], \"client\": client},\n",
    "        \"continuation\": next_data[\"token\"],\n",
    "    }\n",
    "    response = session.post(api_endpoint, params={\"key\": api_key}, json=data)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def get_json_from_html(html: str, key: str, num_chars: int = 2, stop: str = '\"') -> str:\n",
    "    pos_begin = html.find(key) + len(key) + num_chars\n",
    "    pos_end = html.find(stop, pos_begin)\n",
    "    return html[pos_begin:pos_end]\n",
    "\n",
    "\n",
    "def get_next_data(data: dict, sort_by: str = None) -> dict:\n",
    "    # Youtube, please don't change the order of these\n",
    "    sort_by_map = {\n",
    "        \"newest\": 0, \n",
    "        \"popular\": 1,\n",
    "        \"oldest\": 2, \n",
    "    }\n",
    "    if sort_by and sort_by != \"newest\":\n",
    "        endpoint = next(\n",
    "            search_dict(data, \"feedFilterChipBarRenderer\"), None)[\"contents\"][sort_by_map[sort_by]][\"chipCloudChipRenderer\"][\"navigationEndpoint\"]\n",
    "    else:\n",
    "        endpoint = next(search_dict(data, \"continuationEndpoint\"), None)\n",
    "    if not endpoint:\n",
    "        return None\n",
    "    next_data = {\n",
    "        \"token\": endpoint[\"continuationCommand\"][\"token\"],\n",
    "        \"click_params\": {\"clickTrackingParams\": endpoint[\"clickTrackingParams\"]},\n",
    "    }\n",
    "\n",
    "    return next_data\n",
    "\n",
    "\n",
    "def search_dict(partial: dict, search_key: str) -> Generator[dict, None, None]:\n",
    "    stack = [partial]\n",
    "    while stack:\n",
    "        current_item = stack.pop(0)\n",
    "        if isinstance(current_item, dict):\n",
    "            for key, value in current_item.items():\n",
    "                if key == search_key:\n",
    "                    yield value\n",
    "                else:\n",
    "                    stack.append(value)\n",
    "        elif isinstance(current_item, list):\n",
    "            for value in current_item:\n",
    "                stack.append(value)\n",
    "\n",
    "\n",
    "def get_videos_items(data: dict, selector: str) -> Generator[dict, None, None]:\n",
    "    return search_dict(data, selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb987607-86e2-42ef-a722-6b8b59a75d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import scrapetube\n",
    "import time\n",
    "\n",
    "def get_short_videos(channel_id: str, limit: int = None, sleep: int = 1):\n",
    "    videos = scrapetube.get_channel(channel_id)\n",
    "    count = 0\n",
    "    for video in videos:\n",
    "        if video.get('shortBylineText'):\n",
    "            yield video\n",
    "            count += 1\n",
    "            if limit and count >= limit:\n",
    "                break\n",
    "        time.sleep(sleep)\n",
    "\n",
    "# Get short videos from a channel\n",
    "channel_id = \"UC6nQxVomo-B2n5-_mYwLv9g\"\n",
    "short_videos = get_short_videos(channel_id, limit=10)\n",
    "\n",
    "# Or, search for short videos\n",
    "query = \"excel shorts\"\n",
    "short_videos = scrapetube.get_search(query)\n",
    "\n",
    "# Print video details\n",
    "for video in short_videos:\n",
    "    print(\"Video ID:\", f\"https://www.youtube.com/watch?v={video['videoId']}\")\n",
    "    print(\"Video Title:\", video['title'])\n",
    "    print(\"Video Description:\", video.get('description', ''))\n",
    "    print(\"Video Thumbnail:\", video['thumbnail'])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55335735-a878-4342-8ecb-235e1c71386d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
